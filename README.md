# gen-ai-demo
This is a small demo created for showing the different ways to use generative AI. It utilizes VScode, Continue plug-in as the frontend and Ollama, Gemini, and Groq as AI model providers.

## Table of Contents
- [Overview](#overview)
- [Features](#features)
- [AI Models Used](#ai-models-used)
- [Frontend Used](#frontend-used)

## Overview
This generative AI demo is designed to showcase the various applications of AI models. Users can interact with the demo through a VScode Continue plug-in frontend, allowing for an immersive and intuitive experience.

## Features
- Users can input text prompts and receive generated responses from Ollama, Gemini, and Groq AI models.
- Support for multiple AI models, allowing users to compare and contrast results.
- A user-friendly interface for experimenting with generative AI.

## AI Models providers used
This project utilizes the following AI model providers:

* **OLLAMA**: A state-of-the-art offline LLM provider.
* **GEMINI**: A responsive and readable text generation model by Google.
* **GROQ**: A very fast AI model inference provider.

## Frontend Used
This demo leverages the VScode Continue plug-in as its frontend, providing a versatile and interactive user experience.
